{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.8/site-packages (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84213804fef344ef8a0569a0a9a77272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=629.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db8daa1d7264e30a1b1ca86e2649214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267844284.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa654eb8f1054842bd1233fcd6174905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998782277107239}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(\"I enjoyed dinner last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996238946914673}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(\"I didn't care for the dessert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0df2732a2dc450c903a3e208bfe16de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=480.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b94ff56ba8493ba7fbaf809ae78219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=331070498.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8384f385b92d45acb20c054b9c7209ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423592fdcb2c4b41b4987ca72fab360b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b4deabb62341e18fdede2c9bf7f0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "fill_mask = pipeline('fill-mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>I plan to publish today.</s>',\n",
       "  'score': 0.0455012284219265,\n",
       "  'token': 10732,\n",
       "  'token_str': 'Ġpublish'},\n",
       " {'sequence': '<s>I plan to start today.</s>',\n",
       "  'score': 0.03906160220503807,\n",
       "  'token': 386,\n",
       "  'token_str': 'Ġstart'},\n",
       " {'sequence': '<s>I plan to retire today.</s>',\n",
       "  'score': 0.03785478696227074,\n",
       "  'token': 7865,\n",
       "  'token_str': 'Ġretire'},\n",
       " {'sequence': '<s>I plan to write today.</s>',\n",
       "  'score': 0.03532582148909569,\n",
       "  'token': 3116,\n",
       "  'token_str': 'Ġwrite'},\n",
       " {'sequence': '<s>I plan to graduate today.</s>',\n",
       "  'score': 0.030589651316404343,\n",
       "  'token': 5318,\n",
       "  'token_str': 'Ġgraduate'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"I plan to <mask> today.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "\n",
    "bmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "btokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2104 426\n",
      "According to the Larger Sutra of Immeasurable Life, Amitabha was, in very ancient times and possibly in another system of worlds, a monk named Dharmakara. He is described as a former king who, having come into contact with Buddhist teachings through the buddha Lokesvararaja, renounced his throne. He then resolved to become a Buddha and to create a buddhaksetra possessed of many perfections. These resolutions were expressed\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"According to the Larger Sutra of Immeasurable Life, Amitabha was, in very ancient times and possibly in another system of worlds, a monk named Dharmakara. In some versions of the sutra, Dharmakara is described as a former king who, having come into contact with Buddhist teachings through the buddha Lokesvararaja, renounced his throne. He then resolved to become a Buddha and to create a buddhaksetra possessed of many perfections. These resolutions were expressed in his forty-eight vows, which set out the type of Pureland Dharmakara aspired to create, the conditions under which beings might be born into that world, and what kind of beings they would be when reborn there. In the versions of the sutra widely known in China, Vietnam, Korea and Japan, Dharmakara's eighteenth vow was that any being in any universe desiring to be reborn into Amitabha's pure land and calling upon his name with sincerity, even as few as ten times will be guaranteed rebirth there. His nineteenth vow promises that he, together with his bodhisattvas and other blessed Buddhists, will appear before those who, at the moment of death, call upon him. This openness and acceptance of all kinds of people has made belief in pure lands one of the major influences in Mahāyāna Buddhism. Pure Land Buddhism seems to have first become popular in Gandhara, from where it spread to China and influenced by Taoists and Confucian philosophy before spreading to Central and East Asia. The sutra goes on to explain that Amitabha, after accumulating great merit over countless lives, finally achieved buddhahood and created a pure land called Sukhavati. Sukhavati is situated in the uttermost west, beyond the bounds of our own world. By the power of his vows, Amitabha has made it possible for all who call upon him to be reborn into this land, there to undergo instruction by him in the dharma and ultimately become bodhisattvas and buddhas in their turn. From there, these same bodhisattvas and buddhas return to our world to help yet more people. still residing in his land of Sukhavati, whose many virtues and joys are described.\"\"\"\n",
    "binputs = btokenizer.batch_encode_plus([txt],\n",
    "                                       max_length=2048,\n",
    "                                       truncation=True,\n",
    "                                       return_tensors='pt')\n",
    "summary_ids = bmodel.generate(binputs['input_ids'],\n",
    "                              num_beams=4,\n",
    "                              max_length=100,\n",
    "                              early_stopping=False)\n",
    "for ids in summary_ids:\n",
    "    summ = btokenizer.decode(ids,\n",
    "                             skip_special_tokens=True,\n",
    "                             clean_up_tokenization_spaces=False)\n",
    "    print(len(txt), len(summ))\n",
    "    print(summ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The summarization pipeline:\n",
    "from transformers import pipeline\n",
    "summarizer_pipeline = pipeline(\"summarization\")\n",
    "\n",
    "# This is equivalent to:\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelWithLMHead\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bart-large-cnn\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"bart-large-cnn\")\n",
    "summarizer = pipeline(\"summarization\",  model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuralcoref\n",
    "\n",
    "Installation of [neuralcoref](https://github.com/huggingface/neuralcoref) may require downgrading spacy, see [this neuralcoref issue](https://github.com/huggingface/neuralcoref/issues/158#issuecomment-531787500)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "conda create -y --name cope python=3.5\n",
    "conda activate cope\n",
    "pip install spacy==2.1.0\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download en_core_web_lg\n",
    "pip install neuralcoref\n",
    "pip install torch\n",
    "pip install pytorch-transformers\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
